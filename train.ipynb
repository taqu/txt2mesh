{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12648da0-720c-43fa-8110-310b21e5d8b9",
   "metadata": {
    "id": "12648da0-720c-43fa-8110-310b21e5d8b9"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!git clone --recursive https://github.com/taqu/threestudio.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91d56d-c755-4d80-93ad-7cc1561f26c8",
   "metadata": {
    "id": "5c91d56d-c755-4d80-93ad-7cc1561f26c8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fYxHUleMBIDU",
   "metadata": {
    "id": "fYxHUleMBIDU"
   },
   "outputs": [],
   "source": [
    "!suto apt install -y libaio-dev\n",
    "!pip install ninja\n",
    "!pip install lightning==2.0.0 omegaconf==2.3.0 jaxtyping typeguard diffusers transformers accelerate opencv-python tensorboard matplotlib imageio imageio[ffmpeg] trimesh bitsandbytes sentencepiece safetensors huggingface_hub libigl xatlas datasets wandb tomesd\n",
    "!pip install open3d plotly # mesh visualization\n",
    "#!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "!pip install git+https://github.com/KAIR-BAIR/nerfacc.git@v0.5.2\n",
    "!pip install git+https://github.com/NVlabs/nvdiffrast.git\n",
    "!pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch\n",
    "!pip install deepspeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af897647-1406-478a-9df6-adaacb475949",
   "metadata": {
    "id": "af897647-1406-478a-9df6-adaacb475949"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import sys\n",
    "import os\n",
    "import secrets\n",
    "import asyncio\n",
    "import shutil\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "def load_count(filename):\n",
    "    count = 0\n",
    "    try:\n",
    "        with open(filename, mode='r') as f:\n",
    "            for l in f.readlines():\n",
    "                try:\n",
    "                    count = int(l)\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        return count\n",
    "\n",
    "def save_count(filename, count):\n",
    "    try:\n",
    "        with open(filename, mode='w') as f:\n",
    "            f.write(str(count))\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        return\n",
    "\n",
    "async def run_command(command: str, args: list[str]) -> None:\n",
    "    process = await asyncio.create_subprocess_exec(\n",
    "        command,\n",
    "        *args,\n",
    "        env=os.environ,\n",
    "        stdout=asyncio.subprocess.PIPE,\n",
    "        stderr=asyncio.subprocess.PIPE)\n",
    "    while True:\n",
    "        if process.stdout.at_eof() and process.stderr.at_eof():\n",
    "            break;\n",
    "        stdout = (await process.stdout.readline()).decode()\n",
    "        if stdout:\n",
    "            print(stdout, end='', flush=True)\n",
    "        stderr = (await process.stderr.readline()).decode()\n",
    "        if stderr:\n",
    "            print(stderr, end='', flush=True, file=sys.stderr)\n",
    "        await asyncio.sleep(0.25)\n",
    "    await process.communicate()\n",
    "\n",
    "def find_last_checkpoint(path:str) -> str:\n",
    "    if False == os.path.exists(path):\n",
    "        return None\n",
    "    files = os.listdir(path)\n",
    "    dirs = [f for f in files if os.path.isdir(os.path.join(path,f))]\n",
    "    dirs.sort()\n",
    "    if len(dirs)<=0:\n",
    "        return None\n",
    "    check_point = os.path.join(path, dirs[-1], 'ckpts', 'last.ckpt')\n",
    "    return check_point if os.path.exists(check_point) else None\n",
    "\n",
    "def save_last_checkpoint(path:str) -> None:\n",
    "    check_point = find_last_checkpoint('/content/threestudio/outputs/sheep')\n",
    "    if None == check_point:\n",
    "        return\n",
    "    dst_dir = '/content/drive/MyDrive/Sheep/ckpts/'\n",
    "    date = datetime.datetime.utcnow()\n",
    "    dst_path = os.path.join(dst_dir, 'ckpt'+date.strftime('%Y%m%d')+'.ckpt')\n",
    "    shutil.copy(check_point, dst_path)\n",
    "\n",
    "def restore_last_checkpoint(path:str)->None:\n",
    "    try:\n",
    "        file_path = os.path.join(path, 'ckpt*.ckpt')\n",
    "        files = glob.glob(file_path)\n",
    "        if None == files:\n",
    "            return\n",
    "        files.sort()\n",
    "        file_path = os.path.join(path, files[-1])\n",
    "        print(file_path)\n",
    "        shutil.copy(file_path, '/content/last.ckpt')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def save_last_train_count(path:str)->None:\n",
    "    src_path = '/content/train_count.txt'\n",
    "    if False == os.path.exists(src_path):\n",
    "        return\n",
    "    date = datetime.datetime.utcnow()\n",
    "    dst_path = os.path.join(path, 'train_count'+date.strftime('%Y%m%d')+'.txt')\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "def restore_last_train_count(path:str)->None:\n",
    "    try:\n",
    "        file_path = os.path.join(path, 'train_count*.txt')\n",
    "        files = glob.glob(file_path)\n",
    "        if None == files:\n",
    "            return\n",
    "        files.sort()\n",
    "        file_path = os.path.join(path, files[-1])\n",
    "        print(file_path)\n",
    "        shutil.copy(file_path, '/content/train_count.txt')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "prompts = []\n",
    "dataset = datasets.load_dataset(\"FredZhang7/stable-diffusion-prompts-2.47M\")\n",
    "prompts = prompts + dataset['train']['text']\n",
    "\n",
    "dataset = datasets.load_dataset('Gustavosta/Stable-Diffusion-Prompts')\n",
    "prompts = prompts + dataset['train']['Prompt']\n",
    "\n",
    "#dataset = datasets.load_dataset(\"FredZhang7/anime-prompts-180K\")\n",
    "#prompts = prompts + dataset['train']['safebooru_clean']\n",
    "#prompts = prompts + dataset['train']['danbooru_clean']\n",
    "#prompts = prompts + dataset['train']['danbooru_raw']                         \n",
    "\n",
    "dataset = None\n",
    "restore_last_checkpoint('/content/drive/MyDrive/Sheep/ckpts')\n",
    "restore_last_train_count('/content/drive/MyDrive/Sheep/ckpts') \n",
    "count_path = '/content/train_count.txt'\n",
    "train_count = load_count(count_path)\n",
    "print(min(len(prompts), train_count))\n",
    "max_train_count = max(len(prompts), train_count)\n",
    "print(max_train_count)\n",
    "conf_file = os.path.join(os.getcwd(), 'threestudio/configs/prolificdreamer.yaml')\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='128'\n",
    "os.chdir('/content/threestudio')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "#base_config = ['launch.py','--config', conf_file, '--train', '--gpu', '0', 'name=\\\"sheep\\\"','tag=\\\"sheep\\\"', 'data.width=512', 'data.height=512']\n",
    "base_config = ['launch.py','--config', conf_file, '--train', '--gpu', '0', 'name=\\\"sheep\\\"','tag=\\\"sheep\\\"','data.width=64', 'data.height=64']\n",
    "extra_config = [\n",
    "    'trainer.max_steps=10000'\n",
    "    ,'system.guidance.token_merging=true'\n",
    "    ,'trainer.strategy=\\\"deepspeed_stage_2_offload\\\"'\n",
    "    ,'trainer.devices=1'\n",
    "    #,'trainer.precision=\\\"16-mixed\\\"'\n",
    "    ,'trainer.precision=\\\"32\\\"'\n",
    "    ,'system.guidance.enable_attention_slicing=true'\n",
    "    ,'system.guidance.use_deepspeed=true'\n",
    "    ,'system.optimizer.name=\\\"DeepSpeedCPUAdam\\\"'\n",
    "    ,'system.guidance.pretrained_model_name_or_path=\\\"stabilityai/stable-diffusion-2-1-base\\\"'\n",
    "    ,'system.guidance.pretrained_model_name_or_path_lora=\\\"stabilityai/stable-diffusion-2-1\\\"'\n",
    "]\n",
    "#extra_config = ['trainer.max_steps=1', 'trainer.max_epochs=1', 'trainer.fast_dev_run=True', 'data.batch_size=1', 'system.guidance.token_merging=true', 'system.guidance.enable_attention_slicing=true']\n",
    "base_config = base_config + extra_config\n",
    "train_count = 0\n",
    "for i in range(train_count, 1):\n",
    "    seed = secrets.randbits(64)\n",
    "    args = base_config + ['seed='+str(seed)] + ['system.prompt_processor.prompt=' + prompts[i]]\n",
    "    try:\n",
    "        print(args)\n",
    "        await run_command('python3', args)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "    train_count += 1\n",
    "    save_count(count_path, train_count)\n",
    "    save_last_checkpoint('/content/drive/MyDrive/Sheep/ckpts')\n",
    "    save_last_train_count('/content/drive/MyDrive/Sheep/ckpts')\n",
    "os.chdir('/content')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
